# KinectSkeletalTracking
## 环境配置
* opencv2.4.9
* vs2013
* KinectSDK2.0
## 注释
这是一份判断上半身关节点是否被侦测到的代码，如果侦测到右拇指的话，还会显示右拇指到摄像头的距离。
只判断上半身的原因是一共有25个关节点，也就是说全部都判断的话要写25个case，实在太麻烦了。

在这里，为了方便观察，我不仅使用了骨骼数据，同时也将深度数据显示出来，所以一共用到了两种数据源。
而且为了不让代码刷太快，所以控制了时间间隔，每秒1帧。就像之前一样，当同时使用到多种数据源时，为了使得代码清晰，
比较好的办法是实现先把各种数据源的`Reader`准备好，到时候直接拿来用就行。

在把两种数据源都读入到`Frame`之后，首先要做的是利用`BodyFrame`的`GetAndRefreshBodyData()`这个函数把所有信息输出到数组里
。数组的类型是`IBody`，这个类同样包含了很多方法，链接在此。下一步所需要用到的，就是用它里面的`get_IsTracked()`
这个函数来判断当前这一维是否有效。注意不仅需要判断`get`到的bool值，同时也需要通过函数的返回值判断是否get成功。
如果有效，那么接下来就是利用它里面的`GetJoints()`，来把此人的详细关节信息输出到一个`Joint`数组里面。注意Joint是一个结构，而不是一个类。

接下来，就是对关节的详细处理了，首先，每个关节的状态有三种：`TrackingState_NotTracked`、`TrackingState_Inferred`、
`TrackingState_Tracked`,其中第一个和第三个代表的是没有侦测到和侦测到，第二个代表的是推测，
代表它利用一些不太完全的信息推测出此关节点的位置。为了精确起见，我在代码里只接受Tracked这种状态。然后，就是通过JointType这个变量，
来取得关节点的类型，但是JointType是一个枚举量，也就是说只能获得一个int值，所以要再写一个函数来取得关节名称，
这里我只写了上半身的关节点的代码。`Joint`里还有一个`Position`的重要变量没用到，它包含的是此关节点在摄像机坐标系下的X、Y、Z值，
不用太可惜了，所以就用它来判断下右拇指的距离好了。

让人遗憾的是，`SDK 2.0`对拇指的判断非常非常不精确，且不说距离，状态值就非常难以理解了。
当我的双手放到摄像头完全看不到的地方时它还是信誓旦旦的返回了一个`Tracked`，连个`Inferred`都不是，只好寄希望于微软在下一版的SDK中能解决这个问题。
